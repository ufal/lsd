[vars]
prefix="/lnet/ms/projects/LSD/czeng_models"
exp_prefix="{prefix}/models"
src="cs"
tgt="en"
suffix=""
langpair="{src}{tgt}"
data_prefix="{prefix}/data/{langpair}"
src_train_name="train.{src}"
tgt_train_name="train.{tgt}"
src_val_name="val_1500.{src}"
tgt_val_name="val_1500.{tgt}"

[main]
name="Word-Level Transformer on CzEng, {src}-{tgt}"
tf_manager=<tf_manager>
output="tagger-embs"
batch_size=200
# bacth size klidně ětší než 40
epochs=10
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<runner>]
postprocess=None
evaluation=[("tags", evaluators.Accuracy)]
logging_period="5m"
validation_period="30m"
random_seed=1234

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=12
# num_threads: tady nastavit počet vláken -> žere to pak 2x tolik
num_sessions=1
# save_n_best=5

[train_data]
class=dataset.load_dataset_from_files
s_source="/net/projects/LSD/form_pos/cs-ud-train.forms"
s_tags="/net/projects/LSD/form_pos/cs-ud-train.tags"
lazy=True

[val_data]
class=dataset.load_dataset_from_files
s_source="/net/projects/LSD/form_pos/cs-ud-dev.forms.1k"
s_tags="/net/projects/LSD/form_pos/cs-ud-dev.tags.1k"

# test data to muze mit taky ale dev data eval je taky skoro dobrej

[src_vocabulary]
class=vocabulary.from_wordlist
contains_header=False
path="{prefix}/{src}_vocab_25k.tsv"

[tag_vocabulary]
class=vocabulary.from_wordlist
contains_header=False
contains_frequencies=False
path="upostags"

[input_sequence]
class=model.sequence.EmbeddedSequence
vocabulary=<src_vocabulary>
data_id="source"
embedding_size=512
scale_embeddings_by_depth=True
load_checkpoint="embedding.ckpt"

[emb_blocking]
class=model.gradient_blocking.TemporalStatefulView
blocked_object=<input_sequence>

[encoder]
class=encoders.transformer.TransformerEncoder
input_sequence=<emb_blocking>
ff_hidden_size=4096
depth=6
n_heads=16
dropout_keep_prob=0.9
attention_dropout_keep_prob=0.9

[tagger]
class=decoders.SequenceLabeler
encoder=<encoder>
vocabulary=<tag_vocabulary>
data_id="tags"

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<tagger>]
clip_norm=1.0

[runner]
class=runners.LabelRunner
decoder=<tagger>
output_series="tags"

